apiVersion: ai.ruijie.io/v1
kind: LLMService
metadata:
  labels:
    app.kubernetes.io/name: kubeinfer
    app.kubernetes.io/managed-by: kustomize
  name: test-cache-llm
spec:
  model: "mock-model"
  image: "vllm-mock:latest"
  replicas: 3
  gpuMemory: "2Gi"
  cacheStrategy: "shared"
